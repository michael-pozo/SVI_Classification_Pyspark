{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3355aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import ArrayType, IntegerType\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1ce4c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/21 13:44:04 WARN Utils: Your hostname, Michaels-Laptop.local resolves to a loopback address: 127.0.0.1; using 10.0.0.250 instead (on interface en0)\n",
      "24/04/21 13:44:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/21 13:44:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93e55f9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import census dataframe\n",
    "census_df = spark.read.csv('data/NewYork.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f50df78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+--------+----+----+--------+-------+-------+--------+---------+-------+-------+--------+--------+--------+--------+-------+--------+-------+-------+--------+--------+-------+\n",
      "|COUNTY|     AREA_SQMI|E_TOTPOP|E_HU|E_HH|E_POV150|E_UNEMP|E_HBURD|E_NOHSDP|E_UNINSUR|E_AGE65|E_AGE17|E_DISABL|E_SNGPNT|E_LIMENG|E_MINRTY|E_MUNIT|E_MOBILE|E_CROWD|E_NOVEH|E_GROUPQ|SVI_Rank|E_NOINT|\n",
      "+------+--------------+--------+----+----+--------+-------+-------+--------+---------+-------+-------+--------+--------+--------+--------+-------+--------+-------+-------+--------+--------+-------+\n",
      "|Albany|0.914079496512|    2029| 909| 769|     687|    167|    349|     251|      177|    280|    565|     231|     149|      86|    1605|     14|       0|     23|     93|      13|  0.8532|    379|\n",
      "|Albany|0.237787480434|    3263|1861|1382|    1331|     91|    594|     239|      121|    204|    623|     475|     336|      80|    2646|    205|       0|      0|    440|      71|   0.664|    278|\n",
      "|Albany| 0.55656217198|    2153|1039| 913|    1097|    138|    441|     150|       69|    138|    698|     195|     292|       0|    2067|    383|       0|      0|    414|      10|  0.7201|    356|\n",
      "|Albany|0.254633882898|    3016|1503|1135|    1464|    146|    571|     352|       86|    229|    986|     760|     333|     116|    2585|    137|       0|      0|    576|       5|  0.8119|    305|\n",
      "|Albany|1.968324443778|    2931|1903|1585|     727|     85|    665|      92|       54|    595|    415|     327|      48|       0|    1013|    315|       0|      0|    255|      31|  0.3278|    417|\n",
      "+------+--------------+--------+----+----+--------+-------+-------+--------+---------+-------+-------+--------+--------+--------+--------+-------+--------+-------+-------+--------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prefixes of the column names to drop\n",
    "prefixes_to_drop = ['M', 'EP', 'SP', 'F']\n",
    "# Identify columns to drop based on prefixes\n",
    "columns_to_drop = [column for column in census_df.columns if any(column.startswith(prefix) for prefix in prefixes_to_drop)]\n",
    "# Drop the columns identified by prefixes\n",
    "census_df = census_df.drop(*columns_to_drop)\n",
    "\n",
    "# Additional columns to drop by specific names\n",
    "cols_to_drop = ['RPL_THEME1', 'RPL_THEME2', 'RPL_THEME3', 'RPL_THEME4', 'E_DAYPOP',\n",
    "                'E_AFAM', 'E_HISP', 'E_ASIAN', 'E_AIAN', 'E_NHPI','E_TWOMORE', \n",
    "                'E_OTHERRACE', 'ST', 'STATE', 'ST_ABBR', 'STCNTY', 'LOCATION']\n",
    "# Drop the specifically named columns\n",
    "census_df = census_df.drop(*cols_to_drop)\n",
    "\n",
    "#renaming a column\n",
    "census_df = census_df.withColumnRenamed('RPL_THEMES', 'SVI_Rank')  # Ensure the original column name is 'RPL_THEMES'\n",
    "\n",
    "#drop rows with -999 in SVI Rank\n",
    "census_df = census_df.filter(census_df.SVI_Rank != -999) \n",
    "\n",
    "# Show the first 5 rows of the DataFrame to verify changes\n",
    "census_df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f95f8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import covid dataframe\n",
    "covid_df = spark.read.csv('data/United_States_COVID-19_Community_Levels_by_County.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b21cbeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+---------+-----------------+--------------------------+--------------------+------------------------------+-------------------------------+----------------------------------+--------------------+------------------------+------------+\n",
      "|          county|county_fips|    state|county_population|health_service_area_number| health_service_area|health_service_area_population|covid_inpatient_bed_utilization|covid_hospital_admissions_per_100k|covid_cases_per_100k|covid-19_community_level|date_updated|\n",
      "+----------------+-----------+---------+-----------------+--------------------------+--------------------+------------------------------+-------------------------------+----------------------------------+--------------------+------------------------+------------+\n",
      "|  Lincoln County|      55069|Wisconsin|            27593|                       282|Marathon (Wausau)...|                        291401|                            4.7|                              13.4|              177.58|                  Medium|  2022-08-18|\n",
      "|Manitowoc County|      55071|Wisconsin|            78981|                       355|Sheboygan (Sheboy...|                        244410|                            3.4|                               9.8|              169.66|                     Low|  2022-08-18|\n",
      "| Marathon County|      55073|Wisconsin|           135692|                       282|Marathon (Wausau)...|                        291401|                            4.7|                              13.4|              209.30|                    High|  2022-08-18|\n",
      "|   Monroe County|      55081|Wisconsin|            46253|                       290|La Crosse (La Cro...|                        257027|                            3.9|                              15.6|              216.20|                    High|  2022-08-18|\n",
      "|  Portage County|      55097|Wisconsin|            70772|                       400|         Portage, WI|                         70772|                            5.9|                               7.1|              217.60|                  Medium|  2022-08-18|\n",
      "+----------------+-----------+---------+-----------------+--------------------------+--------------------+------------------------------+-------------------------------+----------------------------------+--------------------+------------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "covid_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3806e17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----------+\n",
      "|covid-19_community_level|     COUNTY|\n",
      "+------------------------+-----------+\n",
      "|                  Medium|     Albany|\n",
      "|                     Low|   Allegany|\n",
      "|                     Low|      Bronx|\n",
      "|                    High|     Broome|\n",
      "|                     Low|Cattaraugus|\n",
      "|                  Medium|     Cayuga|\n",
      "|                  Medium| Chautauqua|\n",
      "|                  Medium|    Chemung|\n",
      "|                     Low|   Chenango|\n",
      "|                    High|    Clinton|\n",
      "|                     Low|   Columbia|\n",
      "|                  Medium|   Cortland|\n",
      "|                     Low|   Delaware|\n",
      "|                     Low|   Dutchess|\n",
      "|                  Medium|       Erie|\n",
      "|                  Medium|      Essex|\n",
      "|                    High|   Franklin|\n",
      "|                     Low|     Fulton|\n",
      "|                  Medium|    Genesee|\n",
      "|                     Low|     Greene|\n",
      "+------------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filter covid df for NY only and prepare to merge with census data\n",
    "covid_df = covid_df.filter((covid_df.state == \"New York\") & (covid_df.date_updated == '2022-02-24'))\n",
    "ny_covid_county = covid_df.select('county', 'covid-19_community_level')\n",
    "ny_covid_county = ny_covid_county.withColumn(\"county_name\", F.split(ny_covid_county.county, \" \")[0])\n",
    "ny_covid_county = ny_covid_county.drop('county')\n",
    "ny_covid_county = ny_covid_county.replace({'New': 'New York', 'St.': 'St. Lawrence'}, subset = 'county_name')\n",
    "ny_covid_county = ny_covid_county.withColumnRenamed('county_name', 'COUNTY')\n",
    "\n",
    "ny_covid_county.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be3dc5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+----+----+--------+-------+-------+--------+---------+-------+-------+--------+--------+--------+--------+-------+--------+-------+-------+--------+-------+------+\n",
      "|     AREA_SQMI|E_TOTPOP|E_HU|E_HH|E_POV150|E_UNEMP|E_HBURD|E_NOHSDP|E_UNINSUR|E_AGE65|E_AGE17|E_DISABL|E_SNGPNT|E_LIMENG|E_MINRTY|E_MUNIT|E_MOBILE|E_CROWD|E_NOVEH|E_GROUPQ|E_NOINT|target|\n",
      "+--------------+--------+----+----+--------+-------+-------+--------+---------+-------+-------+--------+--------+--------+--------+-------+--------+-------+-------+--------+-------+------+\n",
      "|0.914079496512|    2029| 909| 769|     687|    167|    349|     251|      177|    280|    565|     231|     149|      86|    1605|     14|       0|     23|     93|      13|    379|     1|\n",
      "|0.237787480434|    3263|1861|1382|    1331|     91|    594|     239|      121|    204|    623|     475|     336|      80|    2646|    205|       0|      0|    440|      71|    278|     1|\n",
      "| 0.55656217198|    2153|1039| 913|    1097|    138|    441|     150|       69|    138|    698|     195|     292|       0|    2067|    383|       0|      0|    414|      10|    356|     1|\n",
      "|0.254633882898|    3016|1503|1135|    1464|    146|    571|     352|       86|    229|    986|     760|     333|     116|    2585|    137|       0|      0|    576|       5|    305|     1|\n",
      "|1.968324443778|    2931|1903|1585|     727|     85|    665|      92|       54|    595|    415|     327|      48|       0|    1013|    315|       0|      0|    255|      31|    417|     1|\n",
      "+--------------+--------+----+----+--------+-------+-------+--------+---------+-------+-------+--------+--------+--------+--------+-------+--------+-------+-------+--------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#join dataframes\n",
    "\n",
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "joint_df = census_df.join(ny_covid_county, on = 'COUNTY', how = 'left'  )\n",
    "joint_df = joint_df.withColumnRenamed('covid-19_community_level', 'target')\n",
    "joint_df = joint_df.drop('COUNTY', 'SVI_Rank')\n",
    "joint_df = joint_df.replace({999: np.nan})\n",
    "\n",
    "joint_df = joint_df.withColumn(\"target\", \n",
    "                   when(col(\"target\") == \"Low\", 0)\n",
    "                   .when(col(\"target\") == \"Medium\", 1)\n",
    "                   .when(col(\"target\") == \"High\", 2)\n",
    "                   .otherwise(None))\n",
    "\n",
    "joint_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fecea30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|target|count|\n",
      "+------+-----+\n",
      "|     0| 3921|\n",
      "|     1| 1054|\n",
      "|     2|  285|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts_df = joint_df.groupBy(\"target\").count().orderBy(col(\"count\").desc())\n",
    "value_counts_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094df3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b369196e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Qoya",
   "language": "python",
   "name": "qoya"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
